# ==========================================
# 1. SETUP ESPERIMENTO E HARDWARE
# ==========================================
exp_name: "final_tr_ppo"
machine_name: "personal"
seed: 789
cuda: 0                 # indice gpu o -1 per cpu
torch_deterministic: true # PPO beneficia del determinismo per la stabilità
wandb: true
worker_id: 0

# ==========================================
# 2. AMBIENTE E CONFIGURAZIONE UNITY
# ==========================================
env_id: "3xlimo"
# Nota: n_envs è rilevato automaticamente da UnityEnvironment, ma qui è utile per riferimento
build_path: "./unity_build/3xlimo_1502_wind/UASRL.exe"
headless: false
test_lib: false
base_time: 1765457030

# Percorsi configurazioni specifiche
agent_config_path: "./cf/agent_train_sfg.yaml"
obstacles_config_path: "./cf/obstacles_simple_safw.yaml"
other_config_path: "./cf/other.yaml"

# ==========================================
# 3. TRAINING FLOW (ROLLOUTS)
# ==========================================
total_timesteps: 500000 # PPO è on-policy, richiede più step totali rispetto a SAC
num_steps: 8192         # Step raccolti per ogni agente prima di un update (Rollout buffer size)
batch_size: 512

# ==========================================
# 4. ARCHITETTURA RETI NEURALI
# ==========================================
input_stack: 4
hidden_dim: 256         # Dimensione layer nascosti (usato sia per Actor che Critic)

# ==========================================
# 5. IPERPARAMETRI PPO
# ==========================================
learning_rate: 0.0003
anneal_lr: true         # Se true, riduce linearmente il LR fino a 0 a fine training

gamma: 0.99             # Discount factor
gae_lambda: 0.95        # Generalized Advantage Estimation (bilancia bias/variance)
clip_coef: 0.2          # Epsilon di clipping per la PPO loss (es. 0.1 - 0.2)
ent_coef: 0.001          # Coefficiente entropia (incoraggia l'esplorazione)
vf_coef: 0.5            # Peso della Loss della Value Function (Critic)
max_grad_norm: 0.5

# lagrangian var
cost_limit: 10.0       # Uguale al safety_threshold di SAC
cost_vf_coef: 0.5      # Valore standard per bilanciare la loss
init_lambda: 0.01      # Inizio "soft" come in SAC
lambda_lr: 0.05        # MOLTO più alto di SAC (vedi spiegazione sotto)
d_safe: 0.3            # Invariato (è una proprietà fisica dell'ambiente)

# ==========================================
# 6. LOGICA DI AGGIORNAMENTO
# ==========================================
update_epochs: 10       # Quante volte (epoche) riutilizzare i dati raccolti per aggiornare le reti