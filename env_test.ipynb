{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c18488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import traceback\n",
    "from collections import deque\n",
    "from pprint import pprint\n",
    "import wandb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28371054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from mlagents_envs.environment import UnityEnvironment, ActionTuple\n",
    "from mlagents_envs.side_channel.environment_parameters_channel import EnvironmentParametersChannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13309826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium import spaces \n",
    "from stable_baselines3.common.buffers import ReplayBuffer\n",
    "\n",
    "from training_utils import *\n",
    "from testing_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5081b2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "\n",
    "def parse_args(default_config_path=\"./config/train_new_obs.yaml\"):\n",
    "    \"\"\"\n",
    "    Parse arguments from CLI or notebook.\n",
    "    - In notebook: usa il default se non passato\n",
    "    - In CLI: permette override dei parametri nel config\n",
    "    \"\"\"\n",
    "    # --- Gestione notebook: evita crash su ipykernel args ---\n",
    "    argv = sys.argv[1:]\n",
    "    # Se siamo in notebook o non Ã¨ passato il config_path, inseriamo il default\n",
    "    if len(argv) == 0 or \"--f=\" in \" \".join(argv):\n",
    "        argv = [default_config_path]\n",
    "\n",
    "    # --- Pre-parser per leggere il config_path ---\n",
    "    pre_parser = argparse.ArgumentParser(add_help=False)\n",
    "    pre_parser.add_argument(\n",
    "        \"config_path\",\n",
    "        type=str,\n",
    "        nargs=\"?\",\n",
    "        default=default_config_path,\n",
    "        help=\"Main config file path\"\n",
    "    )\n",
    "    initial_args, remaining_argv = pre_parser.parse_known_args(argv)\n",
    "    CONFIG_PATH = initial_args.config_path\n",
    "    print(f\"Config path: {CONFIG_PATH}\")\n",
    "\n",
    "    # --- Legge parametri dal file di config ---\n",
    "    file_config_dict = parse_config_file(CONFIG_PATH)\n",
    "\n",
    "    # --- Parser principale ---\n",
    "    parser = argparse.ArgumentParser(description=\"Training Script\")\n",
    "    parser.add_argument(\n",
    "        \"config_path\",\n",
    "        type=str,\n",
    "        nargs=\"?\",\n",
    "        default=CONFIG_PATH,\n",
    "        help=\"Main config file path\"\n",
    "    )\n",
    "\n",
    "    # Aggiunge parametri dal config file, con tipi corretti\n",
    "    for key, value in file_config_dict.items():\n",
    "        if isinstance(value, bool):\n",
    "            parser.add_argument(f\"--{key}\", type=str2bool, default=value)\n",
    "        elif value is None:\n",
    "            parser.add_argument(f\"--{key}\", type=str, default=value)\n",
    "        else:\n",
    "            parser.add_argument(f\"--{key}\", type=type(value), default=value)\n",
    "\n",
    "    # --- Parse finale con remaining_argv per ignorare args extra Jupyter ---\n",
    "    args, unknown = parser.parse_known_args(remaining_argv)\n",
    "    if unknown:\n",
    "        print(\"Ignored unknown args:\", unknown)\n",
    "    return args\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5a11d9",
   "metadata": {},
   "source": [
    "# Testing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60119879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(env, \n",
    "         args, \n",
    "         env_info,\n",
    "\n",
    "         actor,\n",
    "         \n",
    "         BEHAVIOUR_NAME,\n",
    "         STATE_SIZE,\n",
    "         DEVICE\n",
    "        ):\n",
    "\n",
    "    testing_stats = {\n",
    "        \"time/python_time\": RunningMean(),\n",
    "        \"time/unity_time\": RunningMean(),\n",
    "    }\n",
    "\n",
    "    best_reward = -float('inf')\n",
    "\n",
    "    test_data = {}\n",
    "    \n",
    "    episodic_stats = {}\n",
    "    success_stats = {}\n",
    "    failure_stats = {}\n",
    "    \n",
    "    start_time = time.time()\n",
    "    unity_end_time = -1\n",
    "    unity_start_time = -1\n",
    "\n",
    "    global_step = 0\n",
    "    print(f'[{global_step}/{args.total_timesteps}] Starting Training')\n",
    "\n",
    "\n",
    "    obs = collect_data_after_step(env, BEHAVIOUR_NAME, STATE_SIZE)\n",
    "    \n",
    "    while global_step < args.total_timesteps:\n",
    "\n",
    "        # actions for each agent in the environment\n",
    "        # dim = (naagents, action_space)\n",
    "        for id in obs:\n",
    "            agent_obs = obs[id]\n",
    "            \n",
    "            # terminated agents are not considered\n",
    "            if agent_obs[3]:\n",
    "                continue\n",
    "            \n",
    "            action, _, _ = actor.get_action(torch.Tensor([obs[id][0]]).to(DEVICE))\n",
    "            action = action[0].detach().cpu().numpy()\n",
    "            \n",
    "            # memorize the action taken for the next step\n",
    "            agent_obs[2] = action\n",
    "            \n",
    "            # the first dimention of the action is the \"number of agent\"\n",
    "            # Always 1 if \"set_action_for_agent\" is used\n",
    "            a = ActionTuple(continuous=np.array([action]))\n",
    "            env.set_action_for_agent(BEHAVIOUR_NAME, id, a)\n",
    "        \n",
    "        # --- ENVIRONMENT STEP ---\n",
    "        unity_start_time = time.time()\n",
    "        if unity_end_time > 0 and global_step > args.learning_starts:\n",
    "            testing_stats['time/python_time'].update(unity_start_time - unity_end_time)\n",
    "        \n",
    "        env.step()\n",
    "        unity_end_time = time.time()\n",
    "        if global_step > args.learning_starts:\n",
    "            testing_stats['time/unity_time'].update(unity_end_time - unity_start_time)\n",
    "\n",
    "        next_obs = collect_data_after_step(env, BEHAVIOUR_NAME, STATE_SIZE)\n",
    "        \n",
    "        while env_info.stop_msg_queue:\n",
    "                msg = env_info.stop_msg_queue.pop()\n",
    "                \n",
    "                if global_step >= args.learning_starts:\n",
    "                    update_stats_from_message(episodic_stats, success_stats, failure_stats, msg, args.metrics_smoothing)        \n",
    "                    if episodic_stats['ep_count'] % args.metrics_log_interval == 0:\n",
    "                        print_update(global_step, args.total_timesteps, start_time, episodic_stats)\n",
    "                        \n",
    "                        \n",
    "        # crucial step, easy to overlook, update the previous observation\n",
    "        obs = next_obs\n",
    "                \n",
    "        # Step counter\n",
    "        global_step += 1\n",
    "        \n",
    "    return testing_stats, episodic_stats, success_stats, failure_stats, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3139444c",
   "metadata": {},
   "source": [
    "# Start Testing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284b21d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parse_args()\n",
    "agent_config = parse_config_file(args.agent_config_path)\n",
    "obstacles_config = parse_config_file(args.obstacles_config_path)\n",
    "other_config = parse_config_file(args.other_config_path)\n",
    "\n",
    "args.seed = random.randint(0, 2**16)\n",
    "# args.name = generate_funny_name()\n",
    "\n",
    "print('Training with the following parameters:')\n",
    "pprint(vars(args))\n",
    "\n",
    "print('agent_config:')\n",
    "pprint(agent_config)\n",
    "\n",
    "print('obstacles_config:')\n",
    "pprint(obstacles_config)\n",
    "\n",
    "print('other_config:')\n",
    "pprint(other_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b066fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available() and args.cuda >= 0:\n",
    "    # F-string per inserire l'indice: diventa \"cuda:2\"\n",
    "    device_str = f\"cuda:{args.cuda}\"\n",
    "else:\n",
    "    device_str = \"cpu\"\n",
    "\n",
    "DEVICE = torch.device(device_str)\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65d3e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seeding\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "torch.backends.cudnn.deterministic = args.torch_deterministic\n",
    "print(f'Seed: {args.seed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9c1c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the channel\n",
    "env_info = CustomChannel()\n",
    "param_channel = EnvironmentParametersChannel()\n",
    "\n",
    "print('Applying Unity settings from config...')\n",
    "apply_unity_settings(param_channel, agent_config, 'ag_')\n",
    "apply_unity_settings(param_channel, obstacles_config, 'obs_')\n",
    "\n",
    "if args.test_lib:\n",
    "    print('Testing Ended')\n",
    "    exit(0)\n",
    "\n",
    "# env setup\n",
    "print(f'Starting Unity Environment from build: {args.build_path}')\n",
    "# args.build_path\n",
    "env = UnityEnvironment(args.build_path, \n",
    "                       seed=args.seed, \n",
    "                       side_channels=[env_info, param_channel], \n",
    "                       no_graphics=args.headless,\n",
    "                       worker_id=args.worker_id)\n",
    "print('Unity Environment connected.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859e03b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Resetting environment...')\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d00706",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = f\"{args.exp_name}_{int(time.time()) - args.base_time}\"\n",
    "args.run_name = run_name\n",
    "print(f\"Run name: {run_name}\")\n",
    "\n",
    "# start training\n",
    "save_path = './models/' + run_name\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "print('saving to path:', save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53bf2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEHAVIOUR_NAME = other_config['behavior_name'] + '?team=' + other_config['team']\n",
    "\n",
    "RAY_PER_DIRECTION = other_config['rays_per_direction']\n",
    "RAYCAST_MIN = other_config['rays_min_observation']\n",
    "RAYCAST_MAX = other_config['rays_max_observation']\n",
    "RAYCAST_SIZE = 2*RAY_PER_DIRECTION + 1\n",
    "\n",
    "STATE_SIZE = other_config['state_observation_size'] - 1\n",
    "STATE_MIN = other_config['state_min_observation']\n",
    "STATE_MAX = other_config['state_max_observation']\n",
    "\n",
    "ACTION_SIZE = other_config['action_size']\n",
    "ACTION_MIN = other_config['min_action']\n",
    "ACTION_MAX = other_config['max_action']\n",
    "\n",
    "TOTAL_STATE_SIZE = (STATE_SIZE + RAYCAST_SIZE)*args.input_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e034cabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Creating and loading actor and critic networks...')\n",
    "\n",
    "# ===== Actor =====\n",
    "actor = OldDenseActor(\n",
    "    TOTAL_STATE_SIZE,\n",
    "    ACTION_SIZE,\n",
    "    ACTION_MIN,\n",
    "    ACTION_MAX,\n",
    "    args.actor_network_layers\n",
    ").to(DEVICE)\n",
    "\n",
    "# ===== Q Ensemble =====\n",
    "qf_ensemble = [\n",
    "    OldDenseSoftQNetwork(\n",
    "        TOTAL_STATE_SIZE,\n",
    "        ACTION_SIZE,\n",
    "        args.q_network_layers\n",
    "    ).to(DEVICE)\n",
    "    for _ in range(args.q_ensemble_n)\n",
    "]\n",
    "\n",
    "qf_ensemble_target = [\n",
    "    OldDenseSoftQNetwork(\n",
    "        TOTAL_STATE_SIZE,\n",
    "        ACTION_SIZE,\n",
    "        args.q_network_layers\n",
    "    ).to(DEVICE)\n",
    "    for _ in range(args.q_ensemble_n)\n",
    "]\n",
    "\n",
    "# ===== Load saved weights =====\n",
    "load_models(actor, qf_ensemble, qf_ensemble_target, save_path, suffix='_best')\n",
    "\n",
    "# ===== Optimizers (dopo il load) =====\n",
    "actor_optimizer = optim.Adam(actor.parameters(), lr=args.policy_lr)\n",
    "\n",
    "par = []\n",
    "for q in qf_ensemble:\n",
    "    par += list(q.parameters())\n",
    "\n",
    "qf_optimizer = torch.optim.Adam(\n",
    "    par,\n",
    "    lr=args.q_lr\n",
    ")\n",
    "\n",
    "# ===== Obs stack =====\n",
    "obs_stack = DenseStackedObservations(\n",
    "    args.input_stack,\n",
    "    STATE_SIZE + RAYCAST_SIZE,\n",
    "    args.n_envs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bf94ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_stats, episodic_stats, success_stats, failure_stats, test_data = test(env, \n",
    "                                                                           args, \n",
    "                                                                           \n",
    "                                                                           env_info, \n",
    "                                                                           actor, \n",
    "                                                                           \n",
    "                                                                           BEHAVIOUR_NAME, \n",
    "                                                                           STATE_SIZE, \n",
    "                                                                           DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0705382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset to JSON if accumulation is enabled\n",
    "if CONFIG_DICT['accumulate_data']: \n",
    "    \n",
    "    # Recursive helper to convert all numbers into float (JSON safe)\n",
    "    def convert_all_to_float(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            return {k: convert_all_to_float(v) for k, v in obj.items()}\n",
    "        elif isinstance(obj, (list, tuple)):\n",
    "            return [convert_all_to_float(item) for item in obj]\n",
    "        elif isinstance(obj, (np.floating, Decimal)):\n",
    "            return float(obj)\n",
    "        else:\n",
    "            return obj\n",
    "        \n",
    "    # Save dataset with timestamp in filename\n",
    "    with open(f'./results/test_{int(time.time()) - 1751796000}.json', 'w+') as file:\n",
    "        file.write(json.dumps(convert_all_to_float(dataset)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996c8b7d",
   "metadata": {},
   "source": [
    "# Close Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb5d4909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the environment\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".newenv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
