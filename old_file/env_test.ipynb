{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c18488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import traceback\n",
    "from collections import deque\n",
    "from pprint import pprint\n",
    "import wandb\n",
    "import numpy as np\n",
    "from decimal import Decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28371054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from mlagents_envs.environment import UnityEnvironment, ActionTuple\n",
    "from mlagents_envs.side_channel.environment_parameters_channel import EnvironmentParametersChannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13309826",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    }
   ],
   "source": [
    "from gymnasium import spaces \n",
    "from stable_baselines3.common.buffers import ReplayBuffer\n",
    "\n",
    "from training_utils import *\n",
    "from testing_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5081b2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "\n",
    "def parse_args(default_config_path=\"./config/test.yaml\"):\n",
    "    \"\"\"\n",
    "    Parse arguments from CLI or notebook.\n",
    "    - In notebook: usa il default se non passato\n",
    "    - In CLI: permette override dei parametri nel config\n",
    "    \"\"\"\n",
    "    # --- Gestione notebook: evita crash su ipykernel args ---\n",
    "    argv = sys.argv[1:]\n",
    "    # Se siamo in notebook o non Ã¨ passato il config_path, inseriamo il default\n",
    "    if len(argv) == 0 or \"--f=\" in \" \".join(argv):\n",
    "        argv = [default_config_path]\n",
    "\n",
    "    # --- Pre-parser per leggere il config_path ---\n",
    "    pre_parser = argparse.ArgumentParser(add_help=False)\n",
    "    pre_parser.add_argument(\n",
    "        \"config_path\",\n",
    "        type=str,\n",
    "        nargs=\"?\",\n",
    "        default=default_config_path,\n",
    "        help=\"Main config file path\"\n",
    "    )\n",
    "    initial_args, remaining_argv = pre_parser.parse_known_args(argv)\n",
    "    CONFIG_PATH = initial_args.config_path\n",
    "    print(f\"Config path: {CONFIG_PATH}\")\n",
    "\n",
    "    # --- Legge parametri dal file di config ---\n",
    "    file_config_dict = parse_config_file(CONFIG_PATH)\n",
    "\n",
    "    # --- Parser principale ---\n",
    "    parser = argparse.ArgumentParser(description=\"Training Script\")\n",
    "    parser.add_argument(\n",
    "        \"config_path\",\n",
    "        type=str,\n",
    "        nargs=\"?\",\n",
    "        default=CONFIG_PATH,\n",
    "        help=\"Main config file path\"\n",
    "    )\n",
    "\n",
    "    # Aggiunge parametri dal config file, con tipi corretti\n",
    "    for key, value in file_config_dict.items():\n",
    "        if isinstance(value, bool):\n",
    "            parser.add_argument(f\"--{key}\", type=str2bool, default=value)\n",
    "        elif value is None:\n",
    "            parser.add_argument(f\"--{key}\", type=str, default=value)\n",
    "        else:\n",
    "            parser.add_argument(f\"--{key}\", type=type(value), default=value)\n",
    "\n",
    "    # --- Parse finale con remaining_argv per ignorare args extra Jupyter ---\n",
    "    args, unknown = parser.parse_known_args(remaining_argv)\n",
    "    if unknown:\n",
    "        print(\"Ignored unknown args:\", unknown)\n",
    "    return args\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5a11d9",
   "metadata": {},
   "source": [
    "# Testing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21eddb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(env, \n",
    "         env_info,\n",
    "         param_channel,\n",
    "         \n",
    "         args, \n",
    "         agent_config,\n",
    "         obstacles_config,\n",
    "         \n",
    "         actor,\n",
    "         \n",
    "         BEHAVIOUR_NAME,\n",
    "         STATE_SIZE,\n",
    "         RAYCAST_SIZE,\n",
    "         DEVICE\n",
    "        ):\n",
    "    \n",
    "    print('Applying Unity settings from config...')\n",
    "    apply_unity_settings(param_channel, agent_config, 'ag_')\n",
    "    apply_unity_settings(param_channel, obstacles_config, 'obs_')\n",
    "\n",
    "    print('Resetting environment...')\n",
    "    env.reset() \n",
    "    env_info.clear_queue()\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    \n",
    "    # Precompute ray angles for CBF checks\n",
    "    '''angoli_radianti_precalcolati = generate_angles_rad(\n",
    "        10,\n",
    "        90\n",
    "    )'''\n",
    "\n",
    "    start_time = time.time()\n",
    "    unity_end_time = -1\n",
    "    unity_start_time = -1\n",
    "    testing_stats = {\n",
    "        \"python_time\": RunningMean(),\n",
    "        \"unity_time\": RunningMean(),\n",
    "    }\n",
    "    \n",
    "    current_episode = 1\n",
    "    cumulative_obs = {}          # per-agent memory (obs, action, uncertainty info)\n",
    "    running_episodes = {}        # active episodes data\n",
    "    terminated_episodes = []    # finished episodes\n",
    "    \n",
    "    episodic_stats = {}\n",
    "    dataset = []                 # collected dataset\n",
    "        \n",
    "    while current_episode <= args.total_episodes:\n",
    "        \n",
    "        try:  \n",
    "            # --- ENVIRONMENT STEP ---\n",
    "            unity_start_time = time.time()\n",
    "            if unity_end_time > 0:\n",
    "                testing_stats['python_time'].update(unity_start_time - unity_end_time)\n",
    "            \n",
    "            env.step()\n",
    "            \n",
    "            \n",
    "            unity_end_time = time.time()\n",
    "            testing_stats['unity_time'].update(unity_end_time - unity_start_time)\n",
    "            \n",
    "            obs = collect_data_after_step_id(env, BEHAVIOUR_NAME, STATE_SIZE)\n",
    "            \n",
    "            for id in obs:\n",
    "                agent_obs = obs[id]\n",
    "\n",
    "                # Handle terminated agents\n",
    "                if agent_obs[3] == 1:\n",
    "                    if id in cumulative_obs:\n",
    "                        # Remove agent from active lists and finalize episode\n",
    "                        del cumulative_obs[id]\n",
    "                        terminated_episodes.append((agent_obs[4], running_episodes[id])) # tuple (internal_id, episode data)\n",
    "                        del running_episodes[id]\n",
    "                        \n",
    "                    else:\n",
    "                        # Agent killed very early\n",
    "                        terminated_episodes.append((agent_obs[4], []))\n",
    "                        assert id not in running_episodes and id not in cumulative_obs\n",
    "                        \n",
    "                else:\n",
    "                    actual_obs = agent_obs[0]\n",
    "                        \n",
    "                    # Initialize new agent entry\n",
    "                    if id not in cumulative_obs:\n",
    "                        cumulative_obs[id] = [\n",
    "                            args.decision_frame_period, # steps until next decision\n",
    "                            None,   # last obs\n",
    "                            None,   # last action taken\n",
    "                        ]\n",
    "                        \n",
    "                    # Time to decide an action\n",
    "                    if cumulative_obs[id][0] >= args.decision_frame_period:\n",
    "                        cumulative_obs[id][0] = 0\n",
    "                        \n",
    "                        # Update ray observations with frame stacking\n",
    "                        if cumulative_obs[id][1] is None:\n",
    "                            cumulative_obs[id][1] = actual_obs\n",
    "                            corrected_obs = actual_obs\n",
    "                        else:\n",
    "                            corrected_obs = cumulative_obs[id][1][RAYCAST_SIZE + STATE_SIZE:] \n",
    "                            corrected_obs = np.concatenate([corrected_obs, actual_obs[-RAYCAST_SIZE - STATE_SIZE:]])\n",
    "\n",
    "                        # Policy action from actor\n",
    "                        action, _, _ = actor.get_action(torch.Tensor([corrected_obs]).to(DEVICE))\n",
    "                        action = action[0].detach().cpu().numpy()\n",
    "                        \n",
    "                        \n",
    "                        '''# Uncertainty filter (optional)\n",
    "                        if CONFIG_DICT['uncertainty_filter']['enabled']: \n",
    "                            uncertanty_estimate = filter_methods[CONFIG_DICT['uncertainty_filter']['method']](\n",
    "                                corrected_obs, \n",
    "                                action\n",
    "                            )\n",
    "                            cumulative_obs[id][4] = uncertanty_estimate\n",
    "                            cumulative_obs[id][5] = uncertanty_estimate > CONFIG_DICT['uncertainty_filter']['threshold']'''\n",
    "                        \n",
    "                        # Update agent memory\n",
    "                        cumulative_obs[id][1] = corrected_obs\n",
    "                        cumulative_obs[id][2] = action\n",
    "                        \n",
    "                        # Start new episode if not already tracked\n",
    "                        if id not in running_episodes: running_episodes[id] = []\n",
    "                        running_episodes[id].append({\n",
    "                            'obs': corrected_obs,\n",
    "                            # 'u_e': cumulative_obs[id][4],\n",
    "                            # 'uf_activation': cumulative_obs[id][5],\n",
    "                            'action': action,\n",
    "                            'inner_steps': []\n",
    "                        })\n",
    "\n",
    "                    # Use last predicted action by default\n",
    "                    policy_action = cumulative_obs[id][2] \n",
    "                    \n",
    "                    # Control Barrier Function (CBF) correction\n",
    "                    '''\n",
    "                    cbf_action = np.zeros(2)\n",
    "                    if CONFIG_DICT['cbf']['enabled']:\n",
    "                        if CONFIG_DICT['uncertainty_filter']['application'] != 'dynamic':\n",
    "                            cbf_action = CBF_from_obs(\n",
    "                                actual_ray_obs[-1], policy_action, env_info,\n",
    "                                CONFIG_DICT['cbf']['d_safe'],\n",
    "                                CONFIG_DICT['cbf']['alpha'],\n",
    "                                CONFIG_DICT['cbf']['d_safe_mul'],\n",
    "                                angoli_radianti_precalcolati\n",
    "                            )\n",
    "\n",
    "                        else:\n",
    "                            cbf_action = CBF_from_obs(\n",
    "                                actual_ray_obs[-1], policy_action, env_info,\n",
    "                                CONFIG_DICT['cbf']['d_safe'] * min(cumulative_obs[id][4]/CONFIG_DICT['uncertainty_filter']['threshold'], 1),\n",
    "                                CONFIG_DICT['cbf']['alpha'],\n",
    "                                CONFIG_DICT['cbf']['d_safe_mul'],\n",
    "                                angoli_radianti_precalcolati\n",
    "                            )\n",
    "                            \n",
    "                        # Ensure minimum forward velocity\n",
    "                        if policy_action[0] > CONFIG_DICT['cbf']['min_forward']:\n",
    "                            cbf_action[0] = max(CONFIG_DICT['cbf']['min_forward'], cbf_action[0])\n",
    "                        else:\n",
    "                            cbf_action[0] = max(policy_action[0], cbf_action[0])'''\n",
    "                                \n",
    "                    # Check if CBF activated\n",
    "                    # cbf_activation = CONFIG_DICT['cbf']['enabled'] and np.linalg.norm(cbf_action - policy_action) > 0.0001\n",
    "                    # running_episodes[id][-1]['inner_steps'].append([np.linalg.norm(cbf_action - policy_action), cbf_activation])\n",
    "                    \n",
    "                    # Final action selection (UF + CBF logic)\n",
    "                    final_action = policy_action\n",
    "                    '''if CONFIG_DICT['uncertainty_filter']['application'] == 'interpolation':\n",
    "                        interpolation_coeff = min(cumulative_obs[id][4]/CONFIG_DICT['uncertainty_filter']['threshold'], 1)\n",
    "                        final_action = cbf_action * interpolation_coeff + ( 1- interpolation_coeff) * policy_action\n",
    "                    else:  \n",
    "                        if cumulative_obs[id][5] and cbf_activation:\n",
    "                            final_action = cbf_action'''\n",
    "                    \n",
    "                    # Debug visualization (optional)\n",
    "                    if args.send_debug_action:\n",
    "                        env_info.send_agent_action_debug(\n",
    "                            agent_obs[4],\n",
    "                            \n",
    "                            final_action[0], \n",
    "                            final_action[1],\n",
    "                            \n",
    "                            policy_action[0],\n",
    "                            policy_action[1], \n",
    "                            \n",
    "                            False, \n",
    "                            0.0, \n",
    "                            0.0,\n",
    "                            \n",
    "                            False,\n",
    "                            0.0,\n",
    "                            0.0\n",
    "                        ) \n",
    "                                                            \n",
    "                    # Apply final action to environment\n",
    "                    a = ActionTuple(continuous=np.array([final_action]))\n",
    "                    env.set_action_for_agent(\n",
    "                        BEHAVIOUR_NAME, id, a\n",
    "                    )\n",
    "                    \n",
    "                    # Increment frame counter\n",
    "                    cumulative_obs[id][0] += 1\n",
    "        except Exception as e:\n",
    "            print('Execution Ended ?!')\n",
    "            traceback.print_exc() \n",
    "            \n",
    "        new_stop_msgs = []\n",
    "        for msg in env_info.stop_msg_queue:\n",
    "            \n",
    "            t_episode = None\n",
    "            t_episode_index = -1\n",
    "            for external_id, (internal_id, episode_data) in enumerate(terminated_episodes):\n",
    "                if internal_id == msg['id']:\n",
    "                    t_episode = episode_data\n",
    "                    t_episode_index = external_id\n",
    "                    break\n",
    "            if t_episode is None:\n",
    "                new_stop_msgs.append(msg)\n",
    "                continue\n",
    "            # Process terminated episode\n",
    "            \n",
    "\n",
    "            if t_episode == []:\n",
    "                print(current_episode, '- agent killed too early, step', msg['length'])\n",
    "                print(msg)\n",
    "            else:\n",
    "                update_stats_from_message_rm(episodic_stats, None, None, msg)        \n",
    "                if current_episode % args.metrics_log_interval == 0:\n",
    "                    print_update(current_episode, args.total_episodes, start_time, episodic_stats)\n",
    "                \n",
    "                current_episode += 1\n",
    "                \n",
    "                # Save data if required\n",
    "                # saving all obseravtion + action and episode stats\n",
    "                if args.accumulate_data:\n",
    "                    dataset.append(([\n",
    "                        list(element['obs']) + list(element['action'])\n",
    "                        for element in t_episode\n",
    "                    ], msg))\n",
    "            \n",
    "            print(current_episode, msg)\n",
    "            del terminated_episodes[int(t_episode_index)]\n",
    "        env_info.stop_msg_queue = new_stop_msgs\n",
    "              \n",
    "        # Safety check: queue should not grow indefinitely\n",
    "        if len(env_info.stop_msg_queue) > 10:\n",
    "            print('ERRORE')\n",
    "            raise AssertionError('Unexpected queue growth')\n",
    "        \n",
    "    episodic_stats[\"unity_time\"] = testing_stats[\"unity_time\"]\n",
    "    episodic_stats[\"python_time\"] = testing_stats[\"python_time\"]\n",
    "    return episodic_stats, dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3139444c",
   "metadata": {},
   "source": [
    "# Start Testing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "284b21d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config path: ./config/test.yaml\n",
      "Testing with the following parameters:\n",
      "{'accumulate_data': True,\n",
      " 'agent_config_path': './config/agent_test.yaml',\n",
      " 'base_time': 1765457030,\n",
      " 'build_path': './unity_build/1xlimotest_wind/UASRL.exe',\n",
      " 'config_path': './config/test.yaml',\n",
      " 'cuda': 0,\n",
      " 'decision_frame_period': 5,\n",
      " 'headless': False,\n",
      " 'metrics_log_interval': 50,\n",
      " 'metrics_smoothing': 0.9,\n",
      " 'policy_name': 'multy_test_4050747',\n",
      " 'save_path': './results/',\n",
      " 'seed': 1234,\n",
      " 'send_debug_action': True,\n",
      " 'test_name': 'test_name',\n",
      " 'torch_deterministic': True,\n",
      " 'total_episodes': 11,\n",
      " 'train_config_path': './config/train_limo.yaml',\n",
      " 'worker_id': 0}\n",
      "train_config:\n",
      "{'actor_network_layers': [128, 128, 128],\n",
      " 'agent_config_path': './config/agent.yaml',\n",
      " 'alpha': 0.2,\n",
      " 'alpha_lr': 0.0001,\n",
      " 'autotune': True,\n",
      " 'base_time': 1765457030,\n",
      " 'batch_size': 256,\n",
      " 'bootstrap': True,\n",
      " 'bootstrap_batch_proportion': 0.8,\n",
      " 'buffer_size': 100000,\n",
      " 'build_path': './unity_build/3xlimo_wind/UASRL.exe',\n",
      " 'cuda': 0,\n",
      " 'env_id': '3xold',\n",
      " 'exp_name': 'old_pers',\n",
      " 'gamma': 0.995,\n",
      " 'headless': False,\n",
      " 'input_stack': 4,\n",
      " 'learning_starts': 1000,\n",
      " 'loss_log_interval': 500,\n",
      " 'machine_name': 'personal',\n",
      " 'metrics_log_interval': 10,\n",
      " 'metrics_smoothing': 0.98,\n",
      " 'n_envs': 3,\n",
      " 'noise_clip': 0.0,\n",
      " 'obstacles_config_path': './config/obstacles_simple.yaml',\n",
      " 'other_config_path': './config/other.yaml',\n",
      " 'policy_frequency': 4,\n",
      " 'policy_lr': 0.0001,\n",
      " 'q_ensemble_n': 5,\n",
      " 'q_lr': 0.0001,\n",
      " 'q_network_layers': [128, 128, 128],\n",
      " 'reward_scale': 1.0,\n",
      " 'seed': 180618,\n",
      " 'target_entropy': -1.0,\n",
      " 'target_network_update_period': 1,\n",
      " 'tau': 0.005,\n",
      " 'test_lib': False,\n",
      " 'torch_deterministic': False,\n",
      " 'total_timesteps': 80000,\n",
      " 'update_frequency': 1,\n",
      " 'wandb': True,\n",
      " 'worker_id': 0}\n",
      "agent_config:\n",
      "{'action_debug': True,\n",
      " 'cbf_debug': True,\n",
      " 'ema_debug': True,\n",
      " 'ema_range_penalty': 15,\n",
      " 'ema_smoothing': 0.011,\n",
      " 'goal_reward': 10,\n",
      " 'hudHeight': 560,\n",
      " 'hudScale': 1.0,\n",
      " 'hudWidth': 320,\n",
      " 'hudX': 10,\n",
      " 'hudY': 10,\n",
      " 'hud_debug': True,\n",
      " 'max_movement_speed': 1.1,\n",
      " 'max_step': 2000,\n",
      " 'max_turn_speed': 180,\n",
      " 'move_smooth_time': 0.1,\n",
      " 'obstacle_test': False,\n",
      " 'print_debug': False,\n",
      " 'print_every_step': 10000,\n",
      " 'progress_reward': 0.05,\n",
      " 'stagnation_penalty': -0.022,\n",
      " 'step_after_goal': 10,\n",
      " 'wall_hit_penalty': 0}\n",
      "obstacles_config:\n",
      "{'clear_threshold': 3,\n",
      " 'external_walls': True,\n",
      " 'fill_threshold': 6,\n",
      " 'initial_fill_percentage': 0.45,\n",
      " 'moving_obstacles_count': 0,\n",
      " 'smoothing_iterations': 3,\n",
      " 'wall_resolution': 25}\n",
      "other_config:\n",
      "{'action_size': 2,\n",
      " 'behavior_name': 'NavigationAgent',\n",
      " 'max_action': 1.0,\n",
      " 'min_action': -1.0,\n",
      " 'rays_max_observation': 1.0,\n",
      " 'rays_min_observation': -1.0,\n",
      " 'rays_per_direction': 10,\n",
      " 'state_max_observation': 128.0,\n",
      " 'state_min_observation': -128.0,\n",
      " 'state_observation_size': 8,\n",
      " 'team': '0'}\n"
     ]
    }
   ],
   "source": [
    "args = parse_args()\n",
    "train_config = parse_config_file(args.train_config_path)\n",
    "agent_config = parse_config_file(args.agent_config_path)\n",
    "obstacles_config = parse_config_file(train_config[\"obstacles_config_path\"])\n",
    "other_config = parse_config_file(train_config[\"other_config_path\"])\n",
    "\n",
    "# args.seed = random.randint(0, 2**16)\n",
    "# args.name = generate_funny_name()\n",
    "\n",
    "print('Testing with the following parameters:')\n",
    "pprint(vars(args))\n",
    "\n",
    "print('train_config:')\n",
    "pprint(train_config)\n",
    "\n",
    "print('agent_config:')\n",
    "pprint(agent_config)\n",
    "\n",
    "print('obstacles_config:')\n",
    "pprint(obstacles_config)\n",
    "\n",
    "print('other_config:')\n",
    "pprint(other_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b066fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available() and args.cuda >= 0:\n",
    "    # F-string per inserire l'indice: diventa \"cuda:2\"\n",
    "    device_str = f\"cuda:{args.cuda}\"\n",
    "else:\n",
    "    device_str = \"cpu\"\n",
    "\n",
    "DEVICE = torch.device(device_str)\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d65d3e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 1234\n"
     ]
    }
   ],
   "source": [
    "# seeding\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "torch.backends.cudnn.deterministic = args.torch_deterministic\n",
    "print(f'Seed: {args.seed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23d7446",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEHAVIOUR_NAME = other_config['behavior_name'] + '?team=' + other_config['team']\n",
    "\n",
    "RAY_PER_DIRECTION = other_config['rays_per_direction']\n",
    "RAYCAST_MIN = other_config['rays_min_observation']\n",
    "RAYCAST_MAX = other_config['rays_max_observation']\n",
    "RAYCAST_SIZE = 2*RAY_PER_DIRECTION + 1\n",
    "\n",
    "STATE_SIZE = other_config['state_observation_size'] - 1\n",
    "STATE_MIN = other_config['state_min_observation']\n",
    "STATE_MAX = other_config['state_max_observation']\n",
    "\n",
    "ACTION_SIZE = other_config['action_size']\n",
    "ACTION_MIN = other_config['min_action']\n",
    "ACTION_MAX = other_config['max_action']\n",
    "\n",
    "TOTAL_STATE_SIZE = (STATE_SIZE + RAYCAST_SIZE)*train_config['input_stack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a7b340",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p_name in args.policy_names:\n",
    "    \n",
    "    # Create the channel\n",
    "    env_info = CustomChannel()\n",
    "    param_channel = EnvironmentParametersChannel()\n",
    "\n",
    "    for i in range(args.total_episodes):\n",
    "        env_info.send_episode_seed(i+args.seed) # semplice seeding per ogni episodio\n",
    "\n",
    "    # env setup\n",
    "    print(f'Starting Unity Environment from build: {args.build_path}')\n",
    "    # args.build_path\n",
    "    env = UnityEnvironment(None, #args.build_path,\n",
    "                        seed=args.seed,\n",
    "                        side_channels=[env_info, param_channel], \n",
    "                        no_graphics=args.headless,\n",
    "                        worker_id=args.worker_id)\n",
    "    print('Unity Environment connected.')\n",
    "\n",
    "    additional_number = int(time.time()) - train_config[\"base_time\"]\n",
    "    test_name = f\"{args.test_name}_{additional_number}\"\n",
    "    args.test_full_name = test_name\n",
    "\n",
    "    print(f\"Test name: {args.test_full_name}\")\n",
    "    print(f\"Policy name: {p_name}\")\n",
    "    \n",
    "    # start training\n",
    "    summary_save_filepath = args.save_path + args.test_name + \".csv\"\n",
    "    specific_save_filepath = args.save_path + args.test_name + \"/\" + f\"{additional_number}\" + \".json\"\n",
    "    os.makedirs(args.save_path, exist_ok=True)\n",
    "    os.makedirs(args.save_path + args.test_name, exist_ok=True)\n",
    "    \n",
    "    print('Creating and loading actor and critic networks...')\n",
    "\n",
    "    # ===== Actor =====\n",
    "    actor = OldDenseActor(\n",
    "        TOTAL_STATE_SIZE,\n",
    "        ACTION_SIZE,\n",
    "        ACTION_MIN,\n",
    "        ACTION_MAX,\n",
    "        train_config[\"actor_network_layers\"]\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    # ===== Q Ensemble =====\n",
    "    '''qf_ensemble = [\n",
    "        OldDenseSoftQNetwork(\n",
    "            TOTAL_STATE_SIZE,\n",
    "            ACTION_SIZE,\n",
    "            train_config[\"q_network_layers\"]\n",
    "        ).to(DEVICE)\n",
    "        for _ in range(train_config[\"q_ensemble_n\"])\n",
    "    ]\n",
    "\n",
    "    qf_ensemble_target = [\n",
    "        OldDenseSoftQNetwork(\n",
    "            TOTAL_STATE_SIZE,\n",
    "            ACTION_SIZE,\n",
    "            train_config[\"q_network_layers\"]\n",
    "        ).to(DEVICE)\n",
    "        for _ in range(train_config[\"q_ensemble_n\"])\n",
    "    ]'''\n",
    "\n",
    "    # ===== Load saved weights =====\n",
    "    load_models(actor, save_path='./models/' + p_name, suffix='_best')\n",
    "\n",
    "    episodic_stats, dataset = test(env, \n",
    "            env_info,\n",
    "            param_channel,\n",
    "            \n",
    "            args,\n",
    "            agent_config,\n",
    "            obstacles_config,\n",
    "            \n",
    "            actor, \n",
    "            \n",
    "            BEHAVIOUR_NAME,\n",
    "            STATE_SIZE,\n",
    "            RAYCAST_SIZE,\n",
    "            DEVICE)\n",
    "\n",
    "    save_stats_to_csv({}, episodic_stats, summary_save_filepath)\n",
    "    \n",
    "    # Save dataset to JSON if accumulation is enabled\n",
    "    if args.accumulate_data: \n",
    "        \n",
    "        dataset = {\n",
    "            'metadata': {\n",
    "                'test_config': vars(args),\n",
    "                'train_config': train_config,\n",
    "                'agent_config': agent_config,\n",
    "                'obstacles_config': obstacles_config,\n",
    "                'other_config': other_config\n",
    "            },\n",
    "            'data': dataset\n",
    "        }\n",
    "        \n",
    "        # Recursive helper to convert all numbers into float (JSON safe)\n",
    "        def convert_all_to_float(obj):\n",
    "            if isinstance(obj, dict):\n",
    "                return {k: convert_all_to_float(v) for k, v in obj.items()}\n",
    "            elif isinstance(obj, (list, tuple)):\n",
    "                return [convert_all_to_float(item) for item in obj]\n",
    "            elif isinstance(obj, (np.floating, Decimal)):\n",
    "                return float(obj)\n",
    "            else:\n",
    "                return obj\n",
    "            \n",
    "        # Save dataset with timestamp in filename\n",
    "        with open(specific_save_filepath, 'w+') as file:\n",
    "            file.write(json.dumps(convert_all_to_float(dataset)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996c8b7d",
   "metadata": {},
   "source": [
    "# Close Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae74921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb5d4909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the environment\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
