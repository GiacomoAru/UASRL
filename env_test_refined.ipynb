{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c18488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from decimal import Decimal\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from mlagents_envs.base_env import ActionTuple\n",
    "from mlagents_envs.environment import UnityEnvironment\n",
    "\n",
    "from utils_policy_train import *\n",
    "from utils_testing import *\n",
    "from utils_uf_methods import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b6c0ac",
   "metadata": {},
   "source": [
    "# UF Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "301bb7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UE methods\n",
    "uf_methods = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92c72a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilistic Transition Model\n",
    "\n",
    "def prob_world_score(ray_obs, state_obs, \n",
    "                     action,\n",
    "                     prob_model, \n",
    "                     input_mean, input_std):\n",
    "    \n",
    "    # If no action is provided, return neutral score\n",
    "    if action is None:\n",
    "        return 0.0\n",
    "    \n",
    "    # Convert inputs to tensors\n",
    "    ray_obs = torch.tensor(ray_obs)\n",
    "    state_obs = torch.tensor(state_obs)\n",
    "    action = torch.tensor(action)\n",
    "    \n",
    "    # Concatenate all observations and action into a single vector\n",
    "    obs_concat = torch.cat([ray_obs.flatten(), state_obs, action]).unsqueeze(0)\n",
    "    \n",
    "    # Select only the relevant input features (ray stacks, state subset, last 2 features)\n",
    "    x = torch.cat([obs_concat[:, 17:17*4], \n",
    "                   obs_concat[:, 17*4 + 7: 17*4 + 7*4], \n",
    "                   obs_concat[:, -2:]], dim=1)\n",
    "    \n",
    "    # Normalize input with training statistics\n",
    "    x = (x - input_mean) / input_std\n",
    "    \n",
    "    # Forward pass: extract predictive variance only (no gradient)\n",
    "    with torch.no_grad():\n",
    "        _, var = prob_model(x)\n",
    "    var = var[0].sum().detach()\n",
    "    \n",
    "    # Return scalar uncertainty score\n",
    "    return float(var)\n",
    "\n",
    "\n",
    "# Load pre-trained probabilistic world model\n",
    "prob_method = torch.load('./u_e_test/prob_world_method.pth', weights_only=False)\n",
    "prob_world = ProbabilisticWorldModel(**prob_method['model_args'])\n",
    "prob_world.load_state_dict(prob_method['model_parameters'])\n",
    "prob_world.eval()\n",
    "\n",
    "# Register probabilistic world model method inside UF methods\n",
    "uf_methods['prob_world_model'] = lambda ray_obs, state_obs, action: prob_world_score(\n",
    "    ray_obs, state_obs, action, \n",
    "    prob_world,\n",
    "    prob_method['input_mean'], prob_method['input_std']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2e31714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte Carlo Dropout World Model\n",
    "\n",
    "def mcd_world_score(ray_obs, state_obs, \n",
    "                    action,\n",
    "                    mcd_model, \n",
    "                    input_mean, input_std):\n",
    "    \n",
    "    # If no action is provided, return neutral score\n",
    "    if action is None:\n",
    "        return 0.0\n",
    "    \n",
    "    # Convert inputs to tensors\n",
    "    ray_obs = torch.tensor(ray_obs)\n",
    "    state_obs = torch.tensor(state_obs)\n",
    "    action = torch.tensor(action)\n",
    "    \n",
    "    # Concatenate observations and action into a single vector\n",
    "    obs_concat = torch.cat([ray_obs.flatten(), state_obs, action]).unsqueeze(0)\n",
    "    \n",
    "    # Select the relevant subset of features (ray stacks, part of state, last 2 dims)\n",
    "    x = torch.cat([obs_concat[:, 17:17*4], \n",
    "                   obs_concat[:, 17*4 + 7: 17*4 + 7*4], \n",
    "                   obs_concat[:, -2:]], dim=1)\n",
    "    \n",
    "    # Normalize input with training statistics\n",
    "    x = (x - input_mean) / input_std\n",
    "    \n",
    "    # Forward pass with MC Dropout: compute variance across n_samples stochastic runs\n",
    "    with torch.no_grad():\n",
    "        _, var, _ = mcd_model.predict(x, n_samples=20)\n",
    "    var = var[0].sum().detach()\n",
    "    \n",
    "    # Return scalar uncertainty score\n",
    "    return float(var)\n",
    "\n",
    "\n",
    "# Load pre-trained Monte Carlo Dropout world model\n",
    "mcd_method = torch.load('./u_e_test/mcd_world_method.pth', weights_only=False)\n",
    "mcd_world = MCDropoutWorldModel(**mcd_method['model_args'])\n",
    "mcd_world.load_state_dict(mcd_method['model_parameters'])\n",
    "mcd_world.eval()\n",
    "\n",
    "# Register MCD world model method inside UF methods\n",
    "uf_methods['mcd_world_model'] = lambda ray_obs, state_obs, action: mcd_world_score(\n",
    "    ray_obs, state_obs, action,\n",
    "    mcd_world,\n",
    "    mcd_method['input_mean'], mcd_method['input_std']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d905672b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-network Ensemble\n",
    "\n",
    "def qnet_ensemble_score(ray_obs, state_obs, \n",
    "                        action,\n",
    "                        qnet_ens):\n",
    "\n",
    "    # Convert inputs to tensors and add batch dimension\n",
    "    ray_obs = torch.tensor([ray_obs])\n",
    "    state_obs = torch.tensor([state_obs])\n",
    "    action = torch.tensor([action])\n",
    "    \n",
    "    with torch.no_grad():                                          \n",
    "        # Compute Q-values for each model in the ensemble\n",
    "        q_vals = torch.stack([\n",
    "            q(ray_obs, state_obs, action) for q in qnet_ens\n",
    "        ]) \n",
    "\n",
    "    # Compute variance across ensemble predictions (disagreement = uncertainty)\n",
    "    var = torch.var(q_vals.flatten()).detach()\n",
    "    return float(var)\n",
    "\n",
    "\n",
    "# Load pre-trained Q-network ensemble (5 members)\n",
    "qnet_method = torch.load('./u_e_test/qnet_method.pth', weights_only=False)\n",
    "qnet_ensemble = [DenseSoftQNetwork(**qnet_method['model_args']) for _ in range(5)]\n",
    "\n",
    "# Load parameters for each ensemble member\n",
    "for i, q in enumerate(qnet_ensemble):\n",
    "    q.load_state_dict(qnet_method['model_parameters'][i])\n",
    "\n",
    "# Set all networks to evaluation mode\n",
    "for q in qnet_ensemble:\n",
    "    q.eval()\n",
    "\n",
    "# Register Q-ensemble method inside UF methods\n",
    "uf_methods['qnet_ensemble'] = lambda ray_obs, state_obs, action: qnet_ensemble_score(\n",
    "    ray_obs, state_obs, action,\n",
    "    qnet_ensemble\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02355563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Network Distillation\n",
    "\n",
    "def rnd_score(ray_obs, state_obs, \n",
    "              action,\n",
    "              source_model, predictor_model, \n",
    "              input_mean, input_std):\n",
    "    \n",
    "    # Convert inputs to tensors and flatten ray observations\n",
    "    ray_obs = torch.tensor(ray_obs, dtype=torch.float32).flatten()\n",
    "    state_obs = torch.tensor(state_obs, dtype=torch.float32)\n",
    "    x = torch.cat([ray_obs, state_obs]).unsqueeze(0)\n",
    "\n",
    "    # Normalize with training statistics\n",
    "    x = (x - input_mean) / input_std\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Predictor tries to match the fixed random source\n",
    "        pred = predictor_model(x)\n",
    "        target = source_model(x)\n",
    "    \n",
    "    # Compute squared error (MSE) as novelty signal\n",
    "    diff = (pred - target) ** 2\n",
    "    diff = diff[0].sum() * 100  # scaled score\n",
    "    \n",
    "    # Return scalar uncertainty score\n",
    "    return float(diff)\n",
    "\n",
    "\n",
    "# Load pre-trained RND models (source and predictor networks)\n",
    "rnd_method = torch.load('./u_e_test/rnd_method.pth', weights_only=False)\n",
    "rnd_source = RNDNetwork(**rnd_method['model_args'])\n",
    "rnd_predictor = RNDNetwork(**rnd_method['model_args'])\n",
    "\n",
    "# Load parameters for both networks\n",
    "rnd_source.load_state_dict(rnd_method['model_parameters'][0])\n",
    "rnd_predictor.load_state_dict(rnd_method['model_parameters'][1])\n",
    "\n",
    "# Set models to evaluation mode\n",
    "rnd_source.eval()\n",
    "rnd_predictor.eval()\n",
    "\n",
    "# Register RND method inside UF methods\n",
    "uf_methods['rnd'] = lambda ray_obs, state_obs, action: rnd_score(\n",
    "    ray_obs, state_obs, action,\n",
    "    rnd_source, rnd_predictor,\n",
    "    rnd_method['input_mean'], rnd_method['input_std']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54b6e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random baseline\n",
    "def random_score(ray_obs, state_obs, action):\n",
    "    return random.randint(0, 100)\n",
    "\n",
    "\n",
    "# Register random baseline method inside UF methods\n",
    "uf_methods['random'] = random_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b82f6dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0, 0.004123851656913757),\n",
       " (10.0, 0.015988696366548538),\n",
       " (20.0, 0.026410462334752083),\n",
       " (30.0, 0.03678494691848755),\n",
       " (40.0, 0.04911050200462341),\n",
       " (50.0, 0.06513182818889618),\n",
       " (60.0, 0.0857919231057167),\n",
       " (65.0, 0.09955918788909912),\n",
       " (70.0, 0.11650007963180542),\n",
       " (75.0, 0.1394507884979248),\n",
       " (80.0, 0.16976994276046753),\n",
       " (85.0, 0.2213226556777954),\n",
       " (90.0, 0.32138243317604065),\n",
       " (95.0, 0.599012017250061),\n",
       " (99.0, 1.9857155084609985)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qnet_method['percentiles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a32ac32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0, 0.2653093934059143),\n",
       " (10.0, 0.3618978261947632),\n",
       " (20.0, 0.439064085483551),\n",
       " (30.0, 0.5121616721153259),\n",
       " (40.0, 0.5843691825866699),\n",
       " (50.0, 0.657550573348999),\n",
       " (60.0, 0.7382341027259827),\n",
       " (65.0, 0.7862593531608582),\n",
       " (70.0, 0.83976149559021),\n",
       " (75.0, 0.9065841436386108),\n",
       " (80.0, 0.9892659783363342),\n",
       " (85.0, 1.0912400484085083),\n",
       " (90.0, 1.2379447221755981),\n",
       " (95.0, 1.508216142654419),\n",
       " (99.0, 2.256312608718872)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcd_method['percentiles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2053588f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0, 0.13611337542533875),\n",
       " (10.0, 0.24117809534072876),\n",
       " (20.0, 0.32548123598098755),\n",
       " (30.0, 0.40168583393096924),\n",
       " (40.0, 0.4800463616847992),\n",
       " (50.0, 0.5671817660331726),\n",
       " (60.0, 0.6673864722251892),\n",
       " (65.0, 0.7246496677398682),\n",
       " (70.0, 0.791548490524292),\n",
       " (75.0, 0.8710367679595947),\n",
       " (80.0, 0.9697459936141968),\n",
       " (85.0, 1.1040456295013428),\n",
       " (90.0, 1.3025723695755005),\n",
       " (95.0, 1.670838475227356),\n",
       " (99.0, 2.764556884765625)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_method['percentiles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32d5e196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0, 0.07126705348491669),\n",
       " (10.0, 0.30804702639579773),\n",
       " (20.0, 0.5498977899551392),\n",
       " (30.0, 0.7814002633094788),\n",
       " (40.0, 1.021934986114502),\n",
       " (50.0, 1.2947192192077637),\n",
       " (60.0, 1.6259264945983887),\n",
       " (65.0, 1.8369672298431396),\n",
       " (70.0, 2.0703060626983643),\n",
       " (75.0, 2.392136573791504),\n",
       " (80.0, 2.8639121055603027),\n",
       " (85.0, 3.556211471557617),\n",
       " (90.0, 4.722108840942383),\n",
       " (95.0, 7.529963970184326),\n",
       " (99.0, 15.85285758972168)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_method['percentiles']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5a11d9",
   "metadata": {},
   "source": [
    "# Testing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60119879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(CONFIG_DICT, \n",
    "         \n",
    "         env, env_channel,\n",
    "         \n",
    "         filter_methods, \n",
    "         \n",
    "         actor):\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    current_episode = 1\n",
    "    cumulative_obs = {}          # per-agent memory (obs, action, uncertainty info)\n",
    "    running_episodes = {}        # active episodes data\n",
    "    terminated_episodes = []     # finished episodes\n",
    "    stats = []                   # episode statistics\n",
    "    dataset = []                 # collected dataset\n",
    "        \n",
    "    while current_episode <= CONFIG_DICT['tot_episodes']:\n",
    "\n",
    "        env.step()\n",
    "        obs = collect_data_after_step(env, env_info)\n",
    "        \n",
    "        for id in obs:\n",
    "            agent_obs = obs[id]\n",
    "\n",
    "            # Handle terminated agents\n",
    "            if agent_obs[4] == 1:\n",
    "                if id in cumulative_obs:\n",
    "                    # Remove agent from active lists and finalize episode\n",
    "                    del cumulative_obs[id]\n",
    "                    terminated_episodes.append(running_episodes[id])\n",
    "                    del running_episodes[id]\n",
    "                else:\n",
    "                    # Agent killed very early\n",
    "                    terminated_episodes.append([])\n",
    "                    assert id not in running_episodes and id not in cumulative_obs\n",
    "                    \n",
    "            else:\n",
    "                actual_ray_obs = agent_obs[0]\n",
    "                actual_state_obs = agent_obs[1]\n",
    "                    \n",
    "                # Initialize new agent entry\n",
    "                if id not in cumulative_obs:\n",
    "                    cumulative_obs[id] = [\n",
    "                        CONFIG_DICT['decision_frame_period'], # steps until next decision\n",
    "                        None,   # last ray obs\n",
    "                        None,   # last state obs\n",
    "                        None,   # last action taken\n",
    "                        0.0,    # last uncertainty estimate\n",
    "                        True,   # last UF activation\n",
    "                    ]\n",
    "                    \n",
    "                # Time to decide an action\n",
    "                if cumulative_obs[id][0] >= CONFIG_DICT['decision_frame_period']:\n",
    "                    cumulative_obs[id][0] = 0\n",
    "                    \n",
    "                    # Update ray observations with frame stacking\n",
    "                    if cumulative_obs[id][1] is None:\n",
    "                        cumulative_obs[id][1] = actual_ray_obs\n",
    "                        cumulative_ray_obs = actual_ray_obs\n",
    "                    else:\n",
    "                        cumulative_ray_obs = cumulative_obs[id][1][1:, :] \n",
    "                        cumulative_ray_obs = np.concatenate([cumulative_ray_obs, actual_ray_obs[-1:, :]])\n",
    "\n",
    "                    # Update state observations with temporal stacking\n",
    "                    if cumulative_obs[id][2] is None:\n",
    "                        cumulative_obs[id][2] = actual_state_obs\n",
    "                        cumulative_state_obs = actual_state_obs\n",
    "                    else:\n",
    "                        cumulative_state_obs = cumulative_obs[id][2][env_info.settings['behavior_parameters_settings']['observation_size']:] \n",
    "                        cumulative_state_obs = np.concatenate([cumulative_state_obs, actual_state_obs[-env_info.settings['behavior_parameters_settings']['observation_size']:]])\n",
    "                    \n",
    "                    # Policy action from actor\n",
    "                    action, _, _, _ = actor.get_action(\n",
    "                        torch.Tensor([cumulative_ray_obs]).to(device), \n",
    "                        torch.Tensor([cumulative_state_obs]).to(device),\n",
    "                        CONFIG_DICT['var_scale']\n",
    "                    )\n",
    "                    action = action[0].detach().cpu().numpy()\n",
    "                    \n",
    "                    # Uncertainty filter (optional)\n",
    "                    if CONFIG_DICT['uncertainty_filter']['enabled']: \n",
    "                        uncertanty_estimate = filter_methods[CONFIG_DICT['uncertainty_filter']['method']](\n",
    "                            cumulative_ray_obs, \n",
    "                            cumulative_state_obs, \n",
    "                            action\n",
    "                        )\n",
    "                        cumulative_obs[id][4] = uncertanty_estimate\n",
    "                        cumulative_obs[id][5] = uncertanty_estimate > CONFIG_DICT['uncertainty_filter']['threshold']\n",
    "                    \n",
    "                    # Update agent memory\n",
    "                    cumulative_obs[id][1] = cumulative_ray_obs\n",
    "                    cumulative_obs[id][2] = cumulative_state_obs\n",
    "                    cumulative_obs[id][3] = action\n",
    "                    \n",
    "                    # Start new episode if not already tracked\n",
    "                    if id not in running_episodes:\n",
    "                        running_episodes[id] = []\n",
    "                    running_episodes[id].append({\n",
    "                        'ray': cumulative_ray_obs,\n",
    "                        'state': cumulative_state_obs,\n",
    "                        'u_e': cumulative_obs[id][4],\n",
    "                        'uf_activation': cumulative_obs[id][5],\n",
    "                        'action': action,\n",
    "                        'inner_steps': []\n",
    "                    })\n",
    "\n",
    "                # Use last predicted action by default\n",
    "                policy_action = cumulative_obs[id][3] \n",
    "                \n",
    "                # Control Barrier Function (CBF) correction\n",
    "                cbf_action = np.zeros(2)\n",
    "                if CONFIG_DICT['cbf']['enabled']:\n",
    "                    if CONFIG_DICT['uncertainty_filter']['application'] != 'dynamic':\n",
    "                        cbf_action = CBF_from_obs(\n",
    "                            actual_ray_obs[-1], policy_action, env_info,\n",
    "                            CONFIG_DICT['cbf']['d_safe'],\n",
    "                            CONFIG_DICT['cbf']['alpha'],\n",
    "                            CONFIG_DICT['cbf']['d_safe_mul'],\n",
    "                            angoli_radianti_precalcolati\n",
    "                        )\n",
    "\n",
    "                    else:\n",
    "                        cbf_action = CBF_from_obs(\n",
    "                            actual_ray_obs[-1], policy_action, env_info,\n",
    "                            CONFIG_DICT['cbf']['d_safe'] * min(cumulative_obs[id][4]/CONFIG_DICT['uncertainty_filter']['threshold'], 1),\n",
    "                            CONFIG_DICT['cbf']['alpha'],\n",
    "                            CONFIG_DICT['cbf']['d_safe_mul'],\n",
    "                            angoli_radianti_precalcolati\n",
    "                        )\n",
    "                        \n",
    "                    # Ensure minimum forward velocity\n",
    "                    if policy_action[0] > CONFIG_DICT['cbf']['min_forward']:\n",
    "                        cbf_action[0] = max(CONFIG_DICT['cbf']['min_forward'], cbf_action[0])\n",
    "                    else:\n",
    "                        cbf_action[0] = max(policy_action[0], cbf_action[0])\n",
    "                            \n",
    "                # Check if CBF activated\n",
    "                cbf_activation = CONFIG_DICT['cbf']['enabled'] and np.linalg.norm(cbf_action - policy_action) > 0.0001\n",
    "                running_episodes[id][-1]['inner_steps'].append([np.linalg.norm(cbf_action - policy_action), cbf_activation])\n",
    "                \n",
    "                # Final action selection (UF + CBF logic)\n",
    "                final_action = policy_action\n",
    "                if CONFIG_DICT['uncertainty_filter']['application'] == 'interpolation':\n",
    "                    interpolation_coeff = min(cumulative_obs[id][4]/CONFIG_DICT['uncertainty_filter']['threshold'], 1)\n",
    "                    final_action = cbf_action * interpolation_coeff + ( 1- interpolation_coeff) * policy_action\n",
    "                else:  \n",
    "                    if cumulative_obs[id][5] and cbf_activation:\n",
    "                        final_action = cbf_action\n",
    "                \n",
    "                # Debug visualization (optional)\n",
    "                if CONFIG_DICT['send_debug_action']:\n",
    "                    env_debug.send_agent_action_debug(\n",
    "                        final_action[0], final_action[1],\n",
    "                        policy_action[0], policy_action[1], \n",
    "                        cbf_activation, \n",
    "                        cbf_action[0], cbf_action[1],\n",
    "                        cumulative_obs[id][5],\n",
    "                        CONFIG_DICT['uncertainty_filter']['threshold'],\n",
    "                        cumulative_obs[id][4]\n",
    "                    ) \n",
    "                                                          \n",
    "                # Apply final action to environment\n",
    "                a = ActionTuple(continuous=np.array([final_action]))\n",
    "                env.set_action_for_agent(\n",
    "                    env_info.settings['behavior_parameters_settings']['behavior_name'], id, a\n",
    "                )\n",
    "                \n",
    "                # Increment frame counter\n",
    "                cumulative_obs[id][0] += CONFIG_DICT['frame_per_step']\n",
    "        \n",
    "        # Handle finished episodes\n",
    "        if len(env_info.msg_queue) == len(terminated_episodes) and len(terminated_episodes) > 0:\n",
    "            if len(terminated_episodes) == 1:\n",
    "                t_msg = env_info.msg_queue.pop() \n",
    "                t_episode = terminated_episodes.pop()\n",
    "                \n",
    "                if not t_episode:\n",
    "                    print(current_episode, '- agent killed too early, step', t_msg['length'])\n",
    "                else:\n",
    "                    stats.append(extract_stats(t_episode, t_msg, CONFIG_DICT))\n",
    "                    \n",
    "                    if current_episode % CONFIG_DICT['print_interval'] == 0:\n",
    "                        print_stats_light(stats, CONFIG_DICT['tot_episodes'])\n",
    "                        \n",
    "                    current_episode += 1\n",
    "                    \n",
    "                    # Save data if required\n",
    "                    if CONFIG_DICT['accumulate_data']:\n",
    "                        dataset.append([\n",
    "                            list(element['ray'].flatten()) + list(element['state']) + list(element['action'])\n",
    "                            for element in t_episode\n",
    "                        ])\n",
    "                        \n",
    "            else: \n",
    "                # Too many overlapping terminations → reset\n",
    "                print(current_episode, '- sovrapposition, deleting', len(terminated_episodes), 'episodes')\n",
    "                terminated_episodes = []\n",
    "                env_info.msg_queue = []\n",
    "                \n",
    "        # Safety check: queue should not grow indefinitely\n",
    "        if len(env_info.msg_queue) > CONFIG_DICT['message_queue_len_error'] or len(terminated_episodes) > CONFIG_DICT['message_queue_len_error']:\n",
    "            print('ERRORE')\n",
    "            raise AssertionError('Unexpected queue growth')\n",
    "\n",
    "    return stats, dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6bcbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(CONFIG_DICT, \n",
    "         \n",
    "         env, env_channel,\n",
    "         \n",
    "         filter_methods, \n",
    "         \n",
    "         actor):\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    \n",
    "    # Precompute ray angles for CBF checks\n",
    "    angoli_radianti_precalcolati = generate_angles_rad(\n",
    "        env_info.settings['ray_sensor_settings']['rays_per_direction'],\n",
    "        env_info.settings['ray_sensor_settings']['max_ray_degrees']\n",
    "    )\n",
    "\n",
    "    current_episode = 1\n",
    "    cumulative_obs = {}          # per-agent memory (obs, action, uncertainty info)\n",
    "    running_episodes = {}        # active episodes data\n",
    "    terminated_episodes = []     # finished episodes\n",
    "    stats = []                   # episode statistics\n",
    "    dataset = []                 # collected dataset\n",
    "        \n",
    "    while current_episode <= CONFIG_DICT['tot_episodes']:\n",
    "\n",
    "        env.step()\n",
    "        obs = collect_data_after_step(env, env_info)\n",
    "        \n",
    "        for id in obs:\n",
    "            agent_obs = obs[id]\n",
    "\n",
    "            # Handle terminated agents\n",
    "            if agent_obs[4] == 1:\n",
    "                if id in cumulative_obs:\n",
    "                    # Remove agent from active lists and finalize episode\n",
    "                    del cumulative_obs[id]\n",
    "                    terminated_episodes.append(running_episodes[id])\n",
    "                    del running_episodes[id]\n",
    "                else:\n",
    "                    # Agent killed very early\n",
    "                    terminated_episodes.append([])\n",
    "                    assert id not in running_episodes and id not in cumulative_obs\n",
    "                    \n",
    "            else:\n",
    "                actual_ray_obs = agent_obs[0]\n",
    "                actual_state_obs = agent_obs[1]\n",
    "                    \n",
    "                # Initialize new agent entry\n",
    "                if id not in cumulative_obs:\n",
    "                    cumulative_obs[id] = [\n",
    "                        CONFIG_DICT['decision_frame_period'], # steps until next decision\n",
    "                        None,   # last ray obs\n",
    "                        None,   # last state obs\n",
    "                        None,   # last action taken\n",
    "                        0.0,    # last uncertainty estimate\n",
    "                        True,   # last UF activation\n",
    "                    ]\n",
    "                    \n",
    "                # Time to decide an action\n",
    "                if cumulative_obs[id][0] >= CONFIG_DICT['decision_frame_period']:\n",
    "                    cumulative_obs[id][0] = 0\n",
    "                    \n",
    "                    # Update ray observations with frame stacking\n",
    "                    if cumulative_obs[id][1] is None:\n",
    "                        cumulative_obs[id][1] = actual_ray_obs\n",
    "                        cumulative_ray_obs = actual_ray_obs\n",
    "                    else:\n",
    "                        cumulative_ray_obs = cumulative_obs[id][1][1:, :] \n",
    "                        cumulative_ray_obs = np.concatenate([cumulative_ray_obs, actual_ray_obs[-1:, :]])\n",
    "\n",
    "                    # Update state observations with temporal stacking\n",
    "                    if cumulative_obs[id][2] is None:\n",
    "                        cumulative_obs[id][2] = actual_state_obs\n",
    "                        cumulative_state_obs = actual_state_obs\n",
    "                    else:\n",
    "                        cumulative_state_obs = cumulative_obs[id][2][env_info.settings['behavior_parameters_settings']['observation_size']:] \n",
    "                        cumulative_state_obs = np.concatenate([cumulative_state_obs, actual_state_obs[-env_info.settings['behavior_parameters_settings']['observation_size']:]])\n",
    "                    \n",
    "                    # Policy action from actor\n",
    "                    action, _, _, _ = actor.get_action(\n",
    "                        torch.Tensor([cumulative_ray_obs]).to(device), \n",
    "                        torch.Tensor([cumulative_state_obs]).to(device),\n",
    "                        CONFIG_DICT['var_scale']\n",
    "                    )\n",
    "                    action = action[0].detach().cpu().numpy()\n",
    "                    \n",
    "                    # Uncertainty filter (optional)\n",
    "                    if CONFIG_DICT['uncertainty_filter']['enabled']: \n",
    "                        uncertanty_estimate = filter_methods[CONFIG_DICT['uncertainty_filter']['method']](\n",
    "                            cumulative_ray_obs, \n",
    "                            cumulative_state_obs, \n",
    "                            action\n",
    "                        )\n",
    "                        cumulative_obs[id][4] = uncertanty_estimate\n",
    "                        cumulative_obs[id][5] = uncertanty_estimate > CONFIG_DICT['uncertainty_filter']['threshold']\n",
    "                    \n",
    "                    # Update agent memory\n",
    "                    cumulative_obs[id][1] = cumulative_ray_obs\n",
    "                    cumulative_obs[id][2] = cumulative_state_obs\n",
    "                    cumulative_obs[id][3] = action\n",
    "                    \n",
    "                    # Start new episode if not already tracked\n",
    "                    if id not in running_episodes:\n",
    "                        running_episodes[id] = []\n",
    "                    running_episodes[id].append({\n",
    "                        'ray': cumulative_ray_obs,\n",
    "                        'state': cumulative_state_obs,\n",
    "                        'u_e': cumulative_obs[id][4],\n",
    "                        'uf_activation': cumulative_obs[id][5],\n",
    "                        'action': action,\n",
    "                        'inner_steps': []\n",
    "                    })\n",
    "\n",
    "                # Use last predicted action by default\n",
    "                policy_action = cumulative_obs[id][3] \n",
    "                \n",
    "                # Control Barrier Function (CBF) correction\n",
    "                cbf_action = np.zeros(2)\n",
    "                if CONFIG_DICT['cbf']['enabled']:\n",
    "                    if CONFIG_DICT['uncertainty_filter']['application'] != 'dynamic':\n",
    "                        cbf_action = CBF_from_obs(\n",
    "                            actual_ray_obs[-1], policy_action, env_info,\n",
    "                            CONFIG_DICT['cbf']['d_safe'],\n",
    "                            CONFIG_DICT['cbf']['alpha'],\n",
    "                            CONFIG_DICT['cbf']['d_safe_mul'],\n",
    "                            angoli_radianti_precalcolati\n",
    "                        )\n",
    "\n",
    "                    else:\n",
    "                        cbf_action = CBF_from_obs(\n",
    "                            actual_ray_obs[-1], policy_action, env_info,\n",
    "                            CONFIG_DICT['cbf']['d_safe'] * min(cumulative_obs[id][4]/CONFIG_DICT['uncertainty_filter']['threshold'], 1),\n",
    "                            CONFIG_DICT['cbf']['alpha'],\n",
    "                            CONFIG_DICT['cbf']['d_safe_mul'],\n",
    "                            angoli_radianti_precalcolati\n",
    "                        )\n",
    "                        \n",
    "                    # Ensure minimum forward velocity\n",
    "                    if policy_action[0] > CONFIG_DICT['cbf']['min_forward']:\n",
    "                        cbf_action[0] = max(CONFIG_DICT['cbf']['min_forward'], cbf_action[0])\n",
    "                    else:\n",
    "                        cbf_action[0] = max(policy_action[0], cbf_action[0])\n",
    "                            \n",
    "                # Check if CBF activated\n",
    "                cbf_activation = CONFIG_DICT['cbf']['enabled'] and np.linalg.norm(cbf_action - policy_action) > 0.0001\n",
    "                running_episodes[id][-1]['inner_steps'].append([np.linalg.norm(cbf_action - policy_action), cbf_activation])\n",
    "                \n",
    "                # Final action selection (UF + CBF logic)\n",
    "                final_action = policy_action\n",
    "                if CONFIG_DICT['uncertainty_filter']['application'] == 'interpolation':\n",
    "                    interpolation_coeff = min(cumulative_obs[id][4]/CONFIG_DICT['uncertainty_filter']['threshold'], 1)\n",
    "                    final_action = cbf_action * interpolation_coeff + ( 1- interpolation_coeff) * policy_action\n",
    "                else:  \n",
    "                    if cumulative_obs[id][5] and cbf_activation:\n",
    "                        final_action = cbf_action\n",
    "                \n",
    "                # Debug visualization (optional)\n",
    "                if CONFIG_DICT['send_debug_action']:\n",
    "                    env_debug.send_agent_action_debug(\n",
    "                        final_action[0], final_action[1],\n",
    "                        policy_action[0], policy_action[1], \n",
    "                        cbf_activation, \n",
    "                        cbf_action[0], cbf_action[1],\n",
    "                        cumulative_obs[id][5],\n",
    "                        CONFIG_DICT['uncertainty_filter']['threshold'],\n",
    "                        cumulative_obs[id][4]\n",
    "                    ) \n",
    "                                                          \n",
    "                # Apply final action to environment\n",
    "                a = ActionTuple(continuous=np.array([final_action]))\n",
    "                env.set_action_for_agent(\n",
    "                    env_info.settings['behavior_parameters_settings']['behavior_name'], id, a\n",
    "                )\n",
    "                \n",
    "                # Increment frame counter\n",
    "                cumulative_obs[id][0] += CONFIG_DICT['frame_per_step']\n",
    "        \n",
    "        # Handle finished episodes\n",
    "        if len(env_info.msg_queue) == len(terminated_episodes) and len(terminated_episodes) > 0:\n",
    "            if len(terminated_episodes) == 1:\n",
    "                t_msg = env_info.msg_queue.pop() \n",
    "                t_episode = terminated_episodes.pop()\n",
    "                \n",
    "                if not t_episode:\n",
    "                    print(current_episode, '- agent killed too early, step', t_msg['length'])\n",
    "                else:\n",
    "                    stats.append(extract_stats(t_episode, t_msg, CONFIG_DICT))\n",
    "                    \n",
    "                    if current_episode % CONFIG_DICT['print_interval'] == 0:\n",
    "                        print_stats_light(stats, CONFIG_DICT['tot_episodes'])\n",
    "                        \n",
    "                    current_episode += 1\n",
    "                    \n",
    "                    # Save data if required\n",
    "                    if CONFIG_DICT['accumulate_data']:\n",
    "                        dataset.append([\n",
    "                            list(element['ray'].flatten()) + list(element['state']) + list(element['action'])\n",
    "                            for element in t_episode\n",
    "                        ])\n",
    "                        \n",
    "            else: \n",
    "                # Too many overlapping terminations → reset\n",
    "                print(current_episode, '- sovrapposition, deleting', len(terminated_episodes), 'episodes')\n",
    "                terminated_episodes = []\n",
    "                env_info.msg_queue = []\n",
    "                \n",
    "        # Safety check: queue should not grow indefinitely\n",
    "        if len(env_info.msg_queue) > CONFIG_DICT['message_queue_len_error'] or len(terminated_episodes) > CONFIG_DICT['message_queue_len_error']:\n",
    "            print('ERRORE')\n",
    "            raise AssertionError('Unexpected queue growth')\n",
    "\n",
    "    return stats, dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3139444c",
   "metadata": {},
   "source": [
    "# Start Testing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37721b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG DICT\n",
    "CONFIG_DICT = {\n",
    "\n",
    "    'test_name': 'static',\n",
    "    \n",
    "    'send_debug_action': False,  # Solo 1 agente supportato\n",
    "    'accumulate_data': False,\n",
    "    'save_stats':True,\n",
    "    'print_interval':25,\n",
    "    \n",
    "    'message_queue_len_error':10,\n",
    "    'cuda': True,\n",
    "    'tot_episodes': 100,\n",
    "    \n",
    "    'decision_frame_period': 5,\n",
    "    'frame_per_step': 1,\n",
    "    \n",
    "    'var_scale': 2,\n",
    "    \n",
    "    'cbf': {\n",
    "        'd_safe': 1.25, \n",
    "        'd_safe_mul': 2, \n",
    "        'alpha': 5, \n",
    "        'min_forward': 0.05, \n",
    "        'enabled':True\n",
    "    },\n",
    "    \n",
    "    'uncertainty_filter': {\n",
    "        'method': 'mcd_world_model',\n",
    "        'enabled': True,\n",
    "        'application' : 'static', # static, dinamyc, interpolation\n",
    "        'threshold': 0.9085058569908142\n",
    "    },\n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "if CONFIG_DICT['decision_frame_period'] % CONFIG_DICT['frame_per_step'] != 0:\n",
    "    print(\"ATTENZIONE ESPLODERA' TUTTO!!\")\n",
    "CONFIG_DICT['run_name'] = 'base_2179199' # 'base+wp_2183943'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfa50d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#TESTING DICT\\n\\nCONFIG_DICT = {\\n    \\'test_name\\': \\'base\\',\\n    \\n    \\'send_debug_action\\': False,  # Solo 1 agente supportato\\n    \\'accumulate_data\\': False,\\n    \\'save_stats\\': True,\\n    \\'print_interval\\':25,    \\n    \\'message_queue_len_error\\':10,\\n    \\'cuda\\': True,\\n\\n    \\'tot_episodes\\': 100,\\n    \\n    \\'decision_frame_period\\': 5,\\n    \\'frame_per_step\\': 1,\\n    \\n    \\'var_scale\\': 0.9,\\n    \\n    \\n    #\\'cbf\\': {\\'d_safe\\': 1.25, \\'d_safe_mul\\': 2,  \\'alpha\\': 5, \\'min_forward\\': 0.05, \\'enabled\\':True},\\n    \\n    #\\'uncertainty_filter\\': {\\'method\\': \\'mcd_world_model\\',\\'enabled\\': True,\\'threshold\\': 0.8526}\\n}\\n\\nif CONFIG_DICT[\\'decision_frame_period\\'] % CONFIG_DICT[\\'frame_per_step\\'] != 0:\\n    print(\"ATTENZIONE ESPLODERA\\' TUTTO!!\")\\nCONFIG_DICT[\\'run_name\\'] = \\'base_2179199\\' # \\'base+wp_2183943\\'\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#TESTING DICT\n",
    "\n",
    "CONFIG_DICT = {\n",
    "    'test_name': 'base',\n",
    "    \n",
    "    'send_debug_action': False,  # Solo 1 agente supportato\n",
    "    'accumulate_data': False,\n",
    "    'save_stats': True,\n",
    "    'print_interval':25,    \n",
    "    'message_queue_len_error':10,\n",
    "    'cuda': True,\n",
    "\n",
    "    'tot_episodes': 100,\n",
    "    \n",
    "    'decision_frame_period': 5,\n",
    "    'frame_per_step': 1,\n",
    "    \n",
    "    'var_scale': 0.9,\n",
    "    \n",
    "    \n",
    "    #'cbf': {'d_safe': 1.25, 'd_safe_mul': 2,  'alpha': 5, 'min_forward': 0.05, 'enabled':True},\n",
    "    \n",
    "    #'uncertainty_filter': {'method': 'mcd_world_model','enabled': True,'threshold': 0.8526}\n",
    "}\n",
    "\n",
    "if CONFIG_DICT['decision_frame_period'] % CONFIG_DICT['frame_per_step'] != 0:\n",
    "    print(\"ATTENZIONE ESPLODERA' TUTTO!!\")\n",
    "CONFIG_DICT['run_name'] = 'base_2179199' # 'base+wp_2183943'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c558155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the channel\n",
    "env_info = CustomChannel()\n",
    "env_debug = DebugSideChannel()\n",
    "\n",
    "# env setup\n",
    "env = UnityEnvironment(None, seed=random.randint(-100000, 100000), side_channels=[env_info, env_debug])\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f595431",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cicci\\AppData\\Local\\Temp\\ipykernel_1168\\540969086.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  actor.load_state_dict(torch.load(os.path.join(path, 'actor_best.pth')))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DenseActor(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=96, out_features=128, bias=True)\n",
       "    (1-2): 2 x Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (mean_layer): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (logstd_layer): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path to the saved models\n",
    "path = './new_models/' + CONFIG_DICT['run_name']\n",
    "\n",
    "actor = DenseActor((env_info.settings['ray_sensor_settings']['observation_stacks'],\n",
    "                    2*env_info.settings['ray_sensor_settings']['rays_per_direction'] + 1), \n",
    "                env_info.settings['behavior_parameters_settings']['observation_size']*env_info.settings['behavior_parameters_settings']['stacked_vector'], \n",
    "                env_info.settings['behavior_parameters_settings']['continuous_actions'], \n",
    "                env_info.settings['behavior_parameters_settings']['min_action'], \n",
    "                env_info.settings['behavior_parameters_settings']['max_action'], \n",
    "                [128,128,128]).to(device)\n",
    "actor.load_state_dict(torch.load(os.path.join(path, 'actor_best.pth')))\n",
    "actor.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04887a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbf_conf = [{'d_safe': 0, 'd_safe_mul': 0, 'alpha': 0, 'min_forward': 0, 'enabled':False},\n",
    "            {'d_safe': 1.25, 'd_safe_mul': 2, 'alpha': 5, 'min_forward': 0.05, 'enabled':True}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18c9a9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cicci\\AppData\\Local\\Temp\\ipykernel_1168\\2094922283.py:76: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  torch.Tensor([cumulative_ray_obs]).to(device),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ep 25/100] R: 12.50 | S: 1.0000 | C: 0.36 | L: 188.7 | UF: 8.48 | CBF: 31.56 | UF->CBF: 3.28 | CBF->UF: 12.60\n",
      "[ep 50/100] R: 12.73 | S: 1.0000 | C: 0.44 | L: 210.6 | UF: 9.52 | CBF: 30.24 | UF->CBF: 3.10 | CBF->UF: 12.16\n",
      "75 - sovrapposition, deleting 2 episodes\n",
      "[ep 75/100] R: 12.62 | S: 1.0000 | C: 0.41 | L: 219.0 | UF: 10.09 | CBF: 30.85 | UF->CBF: 3.01 | CBF->UF: 11.85\n",
      "[ep 100/100] R: 12.37 | S: 0.9900 | C: 0.51 | L: 236.8 | UF: 12.01 | CBF: 32.25 | UF->CBF: 3.42 | CBF->UF: 13.46\n"
     ]
    }
   ],
   "source": [
    "# DEBUG RUN\n",
    "env_info.reset()\n",
    "env.reset()\n",
    "\n",
    "stats, dataset = test(CONFIG_DICT,\n",
    "                    env, env_info, env_debug,\n",
    "                    uf_methods,\n",
    "                    actor, device)\n",
    "\n",
    "save_dir = f'./phd_results/{CONFIG_DICT[\"test_name\"]}'\n",
    "\n",
    "\n",
    "if CONFIG_DICT['save_stats']:\n",
    "    save_stats(stats, env_info.settings, CONFIG_DICT,\n",
    "            CONFIG_DICT['test_name'] + f'_{int(time.time()) - 1751796000}',\n",
    "            save_dir,\n",
    "            duration=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d9d00c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# TESTING RUN\\n\\nstart_from = \\'SCW_rnd_20pctl_cbf1\\'\\nstart = True\\n\\nuf_thresh = [prob_method[\\'percentiles\\'], mcd_method[\\'percentiles\\'], qnet_method[\\'percentiles\\'], rnd_method[\\'percentiles\\'],\\n             random_percentiles] \\nuf_names = [\\'prob_world_model\\', \\'mcd_world_model\\', \\'qnet_ensemble\\', \\'rnd\\',\\'random\\']\\n\\nfor j, cbf_c in enumerate(cbf_conf):\\n    \\n    if j != 1:\\n        continue\\n    \\n    for i, uf_name in enumerate(uf_names):\\n        \\n        if i != 4:\\n            continue\\n        \\n        save_dir = f\\'./results/MO_{uf_name}\\'\\n        base_name = f\\'MO_{uf_name}\\'\\n        unc_prob = []\\n        percentuali = []\\n        \\n        for perc, val in uf_thresh[i]:\\n            unc_prob.append({\\'method\\': uf_name, \\'enabled\\': True, \\'threshold\\': float(val)})\\n            percentuali.append(perc)\\n        \\n        for i, unc_c in enumerate(unc_prob):\\n            \\n            CONFIG_DICT[\\'test_name\\'] = f\"{base_name}_{int(percentuali[i])}pctl_cbf{j}\"\\n            \\n            CONFIG_DICT[\\'uncertainty_filter\\'] = unc_c\\n            CONFIG_DICT[\\'cbf\\'] = cbf_c\\n\\n            print(\\'Starting\\', CONFIG_DICT[\\'test_name\\'], \\'--\\', CONFIG_DICT[\\'uncertainty_filter\\'][\\'threshold\\'])\\n\\n            if CONFIG_DICT[\\'test_name\\'] == start_from:\\n                start = True\\n            if start:\\n                \\n                done = False\\n                start_time = time.time()\\n                while not done:\\n                    env_info.reset()\\n                    env.reset()\\n                \\n                    try:\\n                        stats, dataset = test(CONFIG_DICT,\\n                                            env, env_info, env_debug,\\n                                            uf_methods,\\n                                            actor, device)\\n                        done = True\\n                    except AssertionError:\\n                        continue\\n\\n                duration = time.time() - start_time\\n                duration_str = str(timedelta(seconds=duration))[:-3]\\n                \\n                if CONFIG_DICT[\\'save_stats\\']:\\n                    save_stats(stats, env_info.settings, CONFIG_DICT,\\n                            CONFIG_DICT[\\'test_name\\'] + f\\'_{int(time.time()) - 1751796000}\\',\\n                            save_dir,\\n                            duration=duration_str)'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# TESTING RUN\n",
    "\n",
    "start_from = 'SCW_rnd_20pctl_cbf1'\n",
    "start = True\n",
    "\n",
    "uf_thresh = [prob_method['percentiles'], mcd_method['percentiles'], qnet_method['percentiles'], rnd_method['percentiles'],\n",
    "             random_percentiles] \n",
    "uf_names = ['prob_world_model', 'mcd_world_model', 'qnet_ensemble', 'rnd','random']\n",
    "\n",
    "for j, cbf_c in enumerate(cbf_conf):\n",
    "    \n",
    "    if j != 1:\n",
    "        continue\n",
    "    \n",
    "    for i, uf_name in enumerate(uf_names):\n",
    "        \n",
    "        if i != 4:\n",
    "            continue\n",
    "        \n",
    "        save_dir = f'./results/MO_{uf_name}'\n",
    "        base_name = f'MO_{uf_name}'\n",
    "        unc_prob = []\n",
    "        percentuali = []\n",
    "        \n",
    "        for perc, val in uf_thresh[i]:\n",
    "            unc_prob.append({'method': uf_name, 'enabled': True, 'threshold': float(val)})\n",
    "            percentuali.append(perc)\n",
    "        \n",
    "        for i, unc_c in enumerate(unc_prob):\n",
    "            \n",
    "            CONFIG_DICT['test_name'] = f\"{base_name}_{int(percentuali[i])}pctl_cbf{j}\"\n",
    "            \n",
    "            CONFIG_DICT['uncertainty_filter'] = unc_c\n",
    "            CONFIG_DICT['cbf'] = cbf_c\n",
    "\n",
    "            print('Starting', CONFIG_DICT['test_name'], '--', CONFIG_DICT['uncertainty_filter']['threshold'])\n",
    "\n",
    "            if CONFIG_DICT['test_name'] == start_from:\n",
    "                start = True\n",
    "            if start:\n",
    "                \n",
    "                done = False\n",
    "                start_time = time.time()\n",
    "                while not done:\n",
    "                    env_info.reset()\n",
    "                    env.reset()\n",
    "                \n",
    "                    try:\n",
    "                        stats, dataset = test(CONFIG_DICT,\n",
    "                                            env, env_info, env_debug,\n",
    "                                            uf_methods,\n",
    "                                            actor, device)\n",
    "                        done = True\n",
    "                    except AssertionError:\n",
    "                        continue\n",
    "\n",
    "                duration = time.time() - start_time\n",
    "                duration_str = str(timedelta(seconds=duration))[:-3]\n",
    "                \n",
    "                if CONFIG_DICT['save_stats']:\n",
    "                    save_stats(stats, env_info.settings, CONFIG_DICT,\n",
    "                            CONFIG_DICT['test_name'] + f'_{int(time.time()) - 1751796000}',\n",
    "                            save_dir,\n",
    "                            duration=duration_str)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0705382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset to JSON if accumulation is enabled\n",
    "if CONFIG_DICT['accumulate_data']: \n",
    "    \n",
    "    # Recursive helper to convert all numbers into float (JSON safe)\n",
    "    def convert_all_to_float(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            return {k: convert_all_to_float(v) for k, v in obj.items()}\n",
    "        elif isinstance(obj, (list, tuple)):\n",
    "            return [convert_all_to_float(item) for item in obj]\n",
    "        elif isinstance(obj, (np.floating, Decimal)):\n",
    "            return float(obj)\n",
    "        else:\n",
    "            return obj\n",
    "        \n",
    "    # Save dataset with timestamp in filename\n",
    "    with open(f'./results/test_{int(time.time()) - 1751796000}.json', 'w+') as file:\n",
    "        file.write(json.dumps(convert_all_to_float(dataset)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996c8b7d",
   "metadata": {},
   "source": [
    "# Close Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb5d4909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the environment\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".newenv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
